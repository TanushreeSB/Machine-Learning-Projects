# -*- coding: utf-8 -*-
"""stocks_prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xg2sncwhdmQy31Nq6jznOkbQKq7EkCv1
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np

import matplotlib.pyplot as plt
# %matplotlib inline

from matplotlib.pylab import rcParams
rcParams['figure.figsize']=20,10
from keras.models import Sequential
from keras.layers import LSTM,Dropout,Dense


from sklearn.preprocessing import MinMaxScaler

df=pd.read_csv("NSE-Tata-Global-Beverages-Limited.csv")
df.head()

df["Date"]=pd.to_datetime(df.Date,format="%Y-%m-%d")
df.index=df['Date']

plt.figure(figsize=(16,8))
plt.plot(df["Close"],label='Close Price history')

data=df.sort_index(ascending=True,axis=0)
new_dataset=pd.DataFrame(index=range(0,len(df)),columns=['Date','Close'])

for i in range(0,len(data)):
    new_dataset["Date"][i]=data['Date'][i]
    new_dataset["Close"][i]=data["Close"][i]

print(new_dataset.columns)

new_dataset = df[['Date', 'Close']].copy()
new_dataset.set_index("Date", inplace=True)

new_dataset = df[['Date', 'Close']].copy()

new_dataset.set_index("Date", inplace=True)

# Convert to numpy array
final_dataset = new_dataset.values

train_data = final_dataset[0:987, :]
valid_data = final_dataset[987:, :]

# Scaling
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(final_dataset)

x_train_data, y_train_data = [], []

for i in range(60, len(train_data)):
    x_train_data.append(scaled_data[i-60:i, 0])
    y_train_data.append(scaled_data[i, 0])

x_train_data = np.array(x_train_data)
y_train_data = np.array(y_train_data)

x_train_data = np.reshape(x_train_data, (x_train_data.shape[0], x_train_data.shape[1], 1))

# Model
lstm_model = Sequential()
lstm_model.add(LSTM(50, return_sequences=True, input_shape=(x_train_data.shape[1], 1)))
lstm_model.add(LSTM(50))
lstm_model.add(Dense(1))

lstm_model.compile(loss='mean_squared_error', optimizer='adam')
lstm_model.fit(x_train_data, y_train_data, epochs=1, batch_size=1, verbose=2)

# Prepare inputs for prediction
inputs_data = new_dataset[len(new_dataset) - len(valid_data) - 60:].values
inputs_data = inputs_data.reshape(-1, 1)
inputs_data = scaler.transform(inputs_data)

X_test = []
for i in range(60, inputs_data.shape[0]):
    X_test.append(inputs_data[i-60:i, 0])

X_test = np.array(X_test)
X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))

# Predict
predicted_closing_price = lstm_model.predict(X_test)
predicted_closing_price = scaler.inverse_transform(predicted_closing_price)

train_data=new_dataset[:987]
valid_data=new_dataset[987:]
valid_data['Predictions']=predicted_closing_price
plt.plot(train_data["Close"])
plt.plot(valid_data[['Close',"Predictions"]])

!pip install dash
!pip3 install dash-html-components
!pip3 install dash-core-components

# =============================
# 1. IMPORTS
# =============================
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, LSTM, Dropout

from dash import Dash, html, dcc
import plotly.graph_objs as go
from flask import Flask

# =============================
# 2. LOAD DATA
# =============================
df = pd.read_csv("stock_data.csv")
df = df[['Close']]

# =============================
# 3. SCALE DATA
# =============================
scaler = MinMaxScaler(feature_range=(0, 1))
scaled_data = scaler.fit_transform(df)

# =============================
# 4. TRAIN-TEST SPLIT
# =============================
training_size = int(len(scaled_data) * 0.8)
train_data = scaled_data[:training_size]
test_data = scaled_data[training_size - 60:]

# =============================
# 5. CREATE DATASET FUNCTION
# =============================
def create_dataset(dataset, time_step=60):
    X, Y = [], []
    for i in range(time_step, len(dataset)):
        X.append(dataset[i - time_step:i, 0])
        Y.append(dataset[i, 0])
    return np.array(X), np.array(Y)

X_train, y_train = create_dataset(train_data)
X_test, y_test = create_dataset(test_data)

# Reshape for LSTM
X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))
X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))

# =============================
# 6. BUILD MODEL
# =============================
lstm_model = Sequential()
lstm_model.add(LSTM(50, return_sequences=True, input_shape=(X_train.shape[1], 1)))
lstm_model.add(Dropout(0.2))
lstm_model.add(LSTM(50))
lstm_model.add(Dropout(0.2))
lstm_model.add(Dense(1))

lstm_model.compile(optimizer="adam", loss="mean_squared_error")

# =============================
# 7. TRAIN MODEL
# =============================
lstm_model.fit(X_train, y_train, epochs=10, batch_size=32)

# =============================
# 8. PREDICT
# =============================
predicted_price = lstm_model.predict(X_test)

# Inverse transform to original scale
predicted_price = scaler.inverse_transform(predicted_price)
real_price = scaler.inverse_transform(y_test.reshape(-1, 1))

# =============================
# 9. DASH APP
# =============================
server = Flask(__name__)
app = Dash(__name__, server=server)

app.layout = html.Div(children=[
    html.H1("Stock Price Prediction Dashboard"),
    dcc.Graph(
        id="price-graph",
        figure={
            "data": [
                go.Scatter(
                    x=list(range(len(real_price))),
                    y=real_price.flatten(),
                    mode="lines",
                    name="Actual Price"
                ),
                go.Scatter(
                    x=list(range(len(predicted_price))),
                    y=predicted_price.flatten(),
                    mode="lines",
                    name="Predicted Price"
                )
            ],
            "layout": go.Layout(title="LSTM Stock Price Prediction")
        }
    )
])

if __name__ == "__main__":
    app.run(debug=True)

import plotly.graph_objs as go

fig = go.Figure()
fig.add_trace(go.Scatter(y=real_price.flatten(), name="Actual"))
fig.add_trace(go.Scatter(y=predicted_price.flatten(), name="Predicted"))
fig.show()

from pyngrok import ngrok

# paste your ngrok token here
!ngrok config add-authtoken 35br5DIWHhETCpH8F6YXeGHxqXR_7T1S7yKsQYnfSgHrjM9Y3

# Open a tunnel to port 8050
public_url = ngrok.connect(8050)
public_url

